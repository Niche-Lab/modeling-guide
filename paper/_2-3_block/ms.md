# Block Cross Validation

Blocking is an essentail approach in experimental design to cotnrol for the variation that can confound the variation of interest. For example, Lahart et al. investigated the dry matter intake of grazing cows using mid-infrared (MIR) spectroscopy techonlogy across multiple herds under different experiment condition (Lahart 2019). Considering the varation between herds is not negligible and may contribute to the cow individual difference of both dry matter intake and mid-infrared spectra, herd should be considered as a blocking factor before evaluating the predicatability on the dry matter intake using MIR spectra. This consideration should be also applied to the model validation. In the previous example, dry matter intake, which is the main interest of the prediction model, has shown to vary by more than one standard deviation between some herds. In a cross validation, if the samples from the same herd are assigned to different folds, of which one fold is used as the test set. There is a high chance that the model will achieve a high accuracy, in which the majority of the model performance come from explaining the inter-herd variation instead of the individaul variation of dry matter intake. In this case, the model performance estimated by the cross validation will be overestimated. To avoid this pitfall, a block cross validation, in which each block (i.e., herd in this example) is used as a fold, is recommended to conduct an unbiased model validation.

The past review of the literature has shown that the block cross validation is an effective approach to evaluate the model performance on an external, or unseen, datasets (Bresolin 2020). In previous example study, three cross validation strategies were compared, 




## Objectives and Hypothesis

The objective of the simulation study is to demonstrate how a regular cross validation (denoted as random CV), which randomly assign the samples to folds without considering the block effects,  could overestimate the model performance. This study also conducts a block cross validation (denoted as block CV), where each block is used as a fold in the cross validation, as the benchmark. The hypothesis is that the model performance estimated by random CV is significantly higher than the estimation by block CV.

## Simulation Design

Similar to the study 1 and 2, a regression task is simulated which has 100 observations for ten predictors $X$ and one response variable ($Y$). Both $X$ and $Y$ are sampled from a standard normal distribution. The block factor is simulated by grouping 20 observations as a block, wich each block has an increasement of 3 units from zero. Among the ten predictors, one of which is replaced as the block levels, which is an integer value from 0 to 4, plus a random noise sampled from a standard normal distribution. This is to simulate a case where the modeled predictors can only capture the block variation, since the expected predicatiblity of using ten random variables ($X$) to predict another random variable (i.e., $Y$) is zero. Two model validation strategies, block CV and random CV, are examined in this study. Both strategies are 5-fold cross validation, in which block CV uses each block as a fold, and random CV randomly assign the samples to each fold (figure x1). The prediction model and the evaluation metric used are linear regression and Pearson's correlation coefficient, respectively. The simulation is repeated 1000 iterations, which $X$ and $Y$ are re-sampled in each iteration. A single tail t-test is used to examine if the mean of the estimated performance is significantly higher than zero. An analysis of variance (ANOVA) table is also computed to confirm if the simulated block variation is significantly larger than the residual variation.

## Result

The ANOVA table (table x) is calculated from one iteration as the demonstration, which show that the simulated data has the block variation significantly greater than the residual variance. A significant difference (p-value < 0.001) of the estimated performance is observed, with a mean of -0.001 and 0.768 for block CV and random CV, respectively. The result is consistent with the hypothesis that the random CV will overestimate the model performance when the block variation is larger than the residual variation.