# Block Cross Validation

In experimental design, blocking is an essentail approach to cotnrol for variation that can confound the primary effects of interest. For example, when investigating the impact of feed composition on the milk production of individual cow, day of lactation should be a blocking facotr (ref) since milk yield is known to change over the course of lactation, and the effect of feed composition may be confounded with the effect of lactation day. Since the variation of blocking factor may contribute to the trait of interest, it is essential to consider the blocking factor when evaluating the model performance. When the inter-block variation is larger than the examined source of interest (i.e., feed composition in the previous example), randomly splitting the data in cross validation may lead to biased estimation of the model performance. Since the model may achieve high accuracy by simply learning the variation of the blocking factor. In this case, a block cross validation, in which each experimental block is used as a test set, is recommended to avoid the overotpimistic conclusion.

Past studies ...

## Objectives and Hypothesis

The objective of the simulation study is to demonstrate how a regular cross validation (denoted as random CV), which randomly assign the samples to folds without considering the block effects,  could overestimate the model performance. This study also conducts a block cross validation (denoted as block CV), where each block is used as a fold in the cross validation, as the benchmark. The hypothesis is that the model performance estimated by random CV is significantly higher than the estimation by block CV.

## Simulation Design

Similar to the study 1 and 2, a regression task is simulated which has 100 observations for ten predictors $X$ and one response variable ($Y$). Both $X$ and $Y$ are sampled from a standard normal distribution. The block factor is simulated by grouping 20 observations as a block, wich each block has an increasement of 3 units from zero. Among the ten predictors, one of which is replaced as the block levels, which is an integer value from 0 to 4, plus a random noise sampled from a standard normal distribution. This is to simulate a case where the modeled predictors can only capture the block variation, since the expected predicatiblity of using ten random variables ($X$) to predict another random variable (i.e., $Y$) is zero. Two model validation strategies, block CV and random CV, are examined in this study. Both strategies are 5-fold cross validation, in which block CV uses each block as a fold, and random CV randomly assign the samples to each fold (figure x1). The prediction model and the evaluation metric used are linear regression and Pearson's correlation coefficient, respectively. The simulation is repeated 1000 iterations, which $X$ and $Y$ are re-sampled in each iteration. A single tail t-test is used to examine if the mean of the estimated performance is significantly higher than zero. An analysis of variance (ANOVA) table is also computed to confirm if the simulated block variation is significantly larger than the residual variation.

## Result

The ANOVA table (table x) is calculated from one iteration as the demonstration, which show that the simulated data has the block variation significantly greater than the residual variance. A significant difference (p-value < 0.001) of the estimated performance is observed, with a mean of -0.001 and 0.768 for block CV and random CV, respectively. The result is consistent with the hypothesis that the random CV will overestimate the model performance when the block variation is larger than the residual variation.