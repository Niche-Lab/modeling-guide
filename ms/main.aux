\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Modeling}{3}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Study Objectives}{3}{subsection.1.2}\protected@file@percent }
\citation{cheng_efficient_2017}
\citation{van_dixhoorn_indicators_2018}
\citation{hastie_elements_2009,cawley_over-fitting_2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Cross Validation}{4}{subsection.1.3}\protected@file@percent }
\citation{hoerl_ridge_1970}
\citation{tibshirani_regression_1996}
\citation{drucker_support_1996}
\citation{abdi_partial_2003}
\citation{breiman_random_2001}
\citation{lecun_generalization_1989}
\citation{ghaffari_metabolomics_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Model Selection}{5}{subsection.1.4}\protected@file@percent }
\citation{hastie_elements_2009}
\citation{rovere_prediction_2021}
\citation{becker_predicting_2021}
\citation{lahart_predicting_2019}
\citation{bresolin_infrared_2020}
\citation{grelet_potential_2020}
\citation{rovere_prediction_2021}
\citation{adriaens_productive_2020,mota_real-time_2022}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Cross Validation Design with Block Effects}{6}{subsection.1.5}\protected@file@percent }
\citation{spoliansky_development_2016,yukun_automatic_2019}
\citation{song_automated_2018,xavier_use_2022}
\citation{rovere_prediction_2021,mota_real-time_2022,mantysaari_body_2019,frizzarin_predicting_2021}
\citation{grelet_potential_2020,appuhamy_prediction_2016,de_souza_predicting_2018}
\citation{van_dixhoorn_indicators_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Model Performance Metrics}{7}{subsection.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.1}Metrics in Regression Tasks}{7}{subsubsection.1.6.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of model performance metrics for regression tasks.\relax }}{7}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:metrics-reg}{{1}{7}{Summary of model performance metrics for regression tasks.\relax }{table.caption.1}{}}
\newlabel{eq_rmse}{{1.1}{7}{Metrics in Regression Tasks}{equation.1.1}{}}
\citation{song_automated_2018,xavier_use_2022}
\newlabel{eq_mae}{{1.2}{8}{Metrics in Regression Tasks}{equation.1.2}{}}
\newlabel{eq_rmspe}{{1.3}{8}{Metrics in Regression Tasks}{equation.1.3}{}}
\newlabel{eq_rsr}{{1.4}{8}{Metrics in Regression Tasks}{equation.1.4}{}}
\newlabel{eq_r}{{1.5}{8}{Metrics in Regression Tasks}{equation.1.5}{}}
\newlabel{eq_R2}{{1.6}{8}{Metrics in Regression Tasks}{equation.1.6}{}}
\citation{de_souza_predicting_2018}
\citation{dorea_mining_2018,rovere_prediction_2021}
\citation{xavier_use_2022}
\citation{grelet_potential_2020}
\citation{mantysaari_body_2019}
\citation{lin_concordance_1989}
\citation{jones_identifying_2022}
\newlabel{eq_ccc}{{1.7}{9}{Metrics in Regression Tasks}{equation.1.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.2}Metrics in Classification Tasks}{10}{subsubsection.1.6.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Confusion matrix for binary classification.\relax }}{10}{table.caption.2}\protected@file@percent }
\newlabel{tab:confusion-matrix}{{2}{10}{Confusion matrix for binary classification.\relax }{table.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Summary of model performance metrics for classification tasks.\relax }}{10}{table.caption.3}\protected@file@percent }
\newlabel{tab:metrics-cls}{{3}{10}{Summary of model performance metrics for classification tasks.\relax }{table.caption.3}{}}
\citation{oleary_invited_2020}
\citation{stojkov_hot_2018}
\citation{oleary_invited_2020,alsaaod_automatic_2019,kang_accurate_2020}
\citation{denholm_predicting_2020}
\citation{kandeel_ability_2019}
\newlabel{eq_TPR}{{1.8}{11}{Metrics in Classification Tasks}{equation.1.8}{}}
\newlabel{eq_TNR}{{1.9}{11}{Metrics in Classification Tasks}{equation.1.9}{}}
\newlabel{eq_precision}{{1.10}{12}{Metrics in Classification Tasks}{equation.1.10}{}}
\newlabel{eq_accuracy}{{1.11}{12}{Metrics in Classification Tasks}{equation.1.11}{}}
\newlabel{eq_f1}{{1.12}{12}{Metrics in Classification Tasks}{equation.1.12}{}}
\newlabel{eq_fbeta}{{1.13}{12}{Metrics in Classification Tasks}{equation.1.13}{}}
\citation{chicco_advantages_2020}
\citation{bowen_early_2021}
\newlabel{eq_f2}{{1.14}{13}{Metrics in Classification Tasks}{equation.1.14}{}}
\newlabel{eq_mcc}{{1.15}{13}{Metrics in Classification Tasks}{equation.1.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Simulation experiments to Understand Model Evaluation Pitfalls}{13}{subsection.1.7}\protected@file@percent }
\citation{metz_note_2020}
\@writefile{toc}{\contentsline {section}{\numberline {2}Materials and Methods}{14}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Study datasets}{14}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Null dataset}{14}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{eq_null}{{2.1}{14}{Null dataset}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Simulated spectral dataset}{14}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{eq_spectral}{{2.2}{14}{Simulated spectral dataset}{equation.2.2}{}}
\citation{chen_independent_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Matrix decomposition of the simulated spectral data. The spectral data matrix $X$ is generated as a linear combination of the score matrix $T$ and the loading matrix $P$, with added noise $E$. The color scale is independently normalized for each matrix.\relax }}{15}{figure.caption.4}\protected@file@percent }
\newlabel{fig:1_sim_data}{{1}{15}{Matrix decomposition of the simulated spectral data. The spectral data matrix $X$ is generated as a linear combination of the score matrix $T$ and the loading matrix $P$, with added noise $E$. The color scale is independently normalized for each matrix.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Overview of the simulated spectral dataset. (a) The spectral data matrix $X$ is visualized with the target variable $y$ categorized by its median value. (b) The autocorrelation plot of the spectral data matrix $X$ shows a bi-modular structure with the least pair-wise correlation around the 100th band.\relax }}{16}{figure.caption.5}\protected@file@percent }
\newlabel{fig:2_sim_data}{{2}{16}{Overview of the simulated spectral dataset. (a) The spectral data matrix $X$ is visualized with the target variable $y$ categorized by its median value. (b) The autocorrelation plot of the spectral data matrix $X$ shows a bi-modular structure with the least pair-wise correlation around the 100th band.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Real-world spectral dataset}{17}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Overview of the real spectral dataset. (a) The spectral data matrix $X$ is visualized with the neutral detergent fiber (NDF) $y$ categorized by its median value. (b) The autocorrelation plot of the spectral data matrix $X$.\relax }}{17}{figure.caption.6}\protected@file@percent }
\newlabel{fig:3_real_data}{{3}{17}{Overview of the real spectral dataset. (a) The spectral data matrix $X$ is visualized with the neutral detergent fiber (NDF) $y$ categorized by its median value. (b) The autocorrelation plot of the spectral data matrix $X$.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Experiment 1: Evaluation bias and variance of cross-validation}{18}{subsection.2.2}\protected@file@percent }
\newlabel{eq_kfoldcv}{{2.3}{19}{Experiment 1: Evaluation bias and variance of cross-validation}{equation.2.3}{}}
\newlabel{eq_insample}{{2.4}{19}{Experiment 1: Evaluation bias and variance of cross-validation}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Experiment 2: Model Selection in Cross-Validation}{19}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Workflow diagram illustrating four cross-validation strategies of feature selection (FS) and hyperparameter tuning (HT), where 0 denotes incorrect implementation and 1 indicates correct practice. $X'$ is the selected feature subset, $\mathbb  {E}[\hat  {g}(f_\mathcal  {D})]$ is the expected generalization performance, $f_\mathcal  {D}$ is the model trained on the training set without being revealed to the test set.\relax }}{20}{figure.caption.7}\protected@file@percent }
\newlabel{fig:s2_schemes}{{4}{20}{Workflow diagram illustrating four cross-validation strategies of feature selection (FS) and hyperparameter tuning (HT), where 0 denotes incorrect implementation and 1 indicates correct practice. $X'$ is the selected feature subset, $\mathbb {E}[\hat {g}(f_\mathcal {D})]$ is the expected generalization performance, $f_\mathcal {D}$ is the model trained on the training set without being revealed to the test set.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Experiment 3: Block Effects in Cross-Validation}{21}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Illustration of fold assignment in block cross validation (left) and random cross validation (right). Folds are color-coded, and the block effect is set to 3 in this example.\relax }}{21}{figure.caption.8}\protected@file@percent }
\newlabel{fig:s3_block}{{5}{21}{Illustration of fold assignment in block cross validation (left) and random cross validation (right). Folds are color-coded, and the block effect is set to 3 in this example.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Experiment 4: Characteristics of Metrics in Regression Tasks}{23}{subsection.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Scatter plots illustrating the relationship between predicted and actual values for 9 combinations of bias and variance, with each parameter set to one of three levels: 0, 2, or 4. The red diagonal line represents the ideal prediction line.\relax }}{23}{figure.caption.9}\protected@file@percent }
\newlabel{fig:s4_regression}{{6}{23}{Scatter plots illustrating the relationship between predicted and actual values for 9 combinations of bias and variance, with each parameter set to one of three levels: 0, 2, or 4. The red diagonal line represents the ideal prediction line.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Experiment 5: Characteristics of Metrics in Classification Tasks}{25}{subsection.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Illustration of the simulation design for evaluating classification metrics under varying balance and confidence thresholds. (a) A 5 × 5 grid of performance metrics, with each cell representing a unique combination of balance and confidence threshold. (b) The prediction probability distribution for positive and negative samples.\relax }}{25}{figure.caption.10}\protected@file@percent }
\newlabel{fig:s5_classification}{{7}{25}{Illustration of the simulation design for evaluating classification metrics under varying balance and confidence thresholds. (a) A 5 × 5 grid of performance metrics, with each cell representing a unique combination of balance and confidence threshold. (b) The prediction probability distribution for positive and negative samples.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results and Discussion}{27}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Experiment 1: The Impact of Estimator Choice and Sample Size on Model Evaluation Reliability}{27}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Evaluation bias from 500 sampling iterations on the null dataset with 10 feature variables. Multiple performance estimators across different sample sizes were color-coded. Two metrics: $r$ and RMSE, were displayed in the column facets.\relax }}{27}{figure.caption.11}\protected@file@percent }
\newlabel{fig:s1_biasvar}{{8}{27}{Evaluation bias from 500 sampling iterations on the null dataset with 10 feature variables. Multiple performance estimators across different sample sizes were color-coded. Two metrics: $r$ and RMSE, were displayed in the column facets.\relax }{figure.caption.11}{}}
\citation{haque_recognition_2023}
\citation{sibiya_computational_2019}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Evaluation bias (mean ± std) for the metrics from 500 sampling iterations. The minimum bias given the same sample size is highlighted in bold. N: training sample size; $r$: Pearson correlation coefficient; $R^2$: coefficient of determination; RMSE: root mean squared error; MAE: mean absolute error. CV: cross-validation; LOOCV: leave-one-out cross-validation.\relax }}{29}{table.caption.12}\protected@file@percent }
\newlabel{tab:eval_bias}{{4}{29}{Evaluation bias (mean ± std) for the metrics from 500 sampling iterations. The minimum bias given the same sample size is highlighted in bold. N: training sample size; $r$: Pearson correlation coefficient; $R^2$: coefficient of determination; RMSE: root mean squared error; MAE: mean absolute error. CV: cross-validation; LOOCV: leave-one-out cross-validation.\relax }{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Evaluation variance (mean ± std) for the metrics from 500 sampling iterations. The minimum variance given the same sample size is highlighted in bold. N: training sample size; $r$: Pearson correlation coefficient; $R^2$: coefficient of determination; RMSE: root mean squared error; MAE: mean absolute error. CV: cross-validation; LOOCV: leave-one-out cross-validation.\relax }}{29}{table.caption.13}\protected@file@percent }
\newlabel{tab:eval_var}{{5}{29}{Evaluation variance (mean ± std) for the metrics from 500 sampling iterations. The minimum variance given the same sample size is highlighted in bold. N: training sample size; $r$: Pearson correlation coefficient; $R^2$: coefficient of determination; RMSE: root mean squared error; MAE: mean absolute error. CV: cross-validation; LOOCV: leave-one-out cross-validation.\relax }{table.caption.13}{}}
\citation{zoph_neural_2017}
\citation{soares_successive_2013}
\citation{zhang_automated_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experiment 2: Misuse of Model Selection Can Lead to Over-Optimistic Performance Estimates}{30}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The evaluation bias of the four combinations of model selection strategies: “FS=0; HT=0”, “FS=0; HT=1”, “FS=1; HT=0”, “FS=1; HT=1” across three datasets. The significance level of the difference between the two strategies is noted as *** < 0.00001.\relax }}{30}{figure.caption.14}\protected@file@percent }
\newlabel{fig:s2_results}{{9}{30}{The evaluation bias of the four combinations of model selection strategies: “FS=0; HT=0”, “FS=0; HT=1”, “FS=1; HT=0”, “FS=1; HT=1” across three datasets. The significance level of the difference between the two strategies is noted as *** < 0.00001.\relax }{figure.caption.14}{}}
\citation{shahinfar_prediction_2019}
\citation{st-pierre_invited_2001}
\citation{de_oliveira_genomic_2020}
\citation{lopez-cruz_leveraging_2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Experiment 3: Overlooking Experimental Block Effects Can Lead to Biased Model Performance Estimates}{32}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Bias in model performance estimation by Block CV and Random CV across 1000 iterations. The dashed line represents the null hypothesis that the mean performance estimate is zero. The significance level is noted as *** < 0.00001.\relax }}{32}{figure.caption.15}\protected@file@percent }
\newlabel{fig:s3_results}{{10}{32}{Bias in model performance estimation by Block CV and Random CV across 1000 iterations. The dashed line represents the null hypothesis that the mean performance estimate is zero. The significance level is noted as *** < 0.00001.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Experiment 4: Characteristics of Metrics in Regression Tasks}{33}{subsection.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The heatmap of different metrics in response to the bias and variance error in regression tasks where the ground truth variance is 4.\relax }}{33}{figure.caption.16}\protected@file@percent }
\newlabel{fig:s4_reg}{{11}{33}{The heatmap of different metrics in response to the bias and variance error in regression tasks where the ground truth variance is 4.\relax }{figure.caption.16}{}}
\citation{buczinski_validation_2018}
\citation{lu_-field_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Experiment 5: Characteristics of Metrics in Classification Tasks}{35}{subsection.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces A 5 × 5 grid of performance metrics, with each cell representing a unique combination of balance and confidence threshold. The inspected metrics focus on one sample distribution at a time. The model is simulated to have higher false positive predictions than false negative predictions with a beta distribution of $\alpha =4$ and $\beta =3$ for the negative class.\relax }}{35}{figure.caption.17}\protected@file@percent }
\newlabel{fig:s5_1}{{12}{35}{A 5 × 5 grid of performance metrics, with each cell representing a unique combination of balance and confidence threshold. The inspected metrics focus on one sample distribution at a time. The model is simulated to have higher false positive predictions than false negative predictions with a beta distribution of $\alpha =4$ and $\beta =3$ for the negative class.\relax }{figure.caption.17}{}}
\citation{zhang_automated_2019,su_advanced_2020}
\citation{gao_retrieval-augmented_2024,salemi_evaluating_2024}
\citation{haque_recognition_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A 5 × 5 grid of performance metrics, with each cell representing a unique combination of balance and confidence threshold. The inspected metrics focus on multiple sample distributions simultaneously. The prediction model is simulated to have higher false positive rate than false negative rate.\relax }}{37}{figure.caption.18}\protected@file@percent }
\newlabel{fig:s5_2}{{13}{37}{A 5 × 5 grid of performance metrics, with each cell representing a unique combination of balance and confidence threshold. The inspected metrics focus on multiple sample distributions simultaneously. The prediction model is simulated to have higher false positive rate than false negative rate.\relax }{figure.caption.18}{}}
\citation{minni_exploring_2024}
\citation{becker_predicting_2021}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{39}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Code Availability}{39}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Acknowledgement}{39}{section.6}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{references}
\bibcite{cheng_efficient_2017}{{1}{}{{}}{{}}}
\bibcite{van_dixhoorn_indicators_2018}{{2}{}{{}}{{}}}
\bibcite{hastie_elements_2009}{{3}{}{{}}{{}}}
\bibcite{cawley_over-fitting_2010}{{4}{}{{}}{{}}}
\bibcite{hoerl_ridge_1970}{{5}{}{{}}{{}}}
\bibcite{tibshirani_regression_1996}{{6}{}{{}}{{}}}
\bibcite{drucker_support_1996}{{7}{}{{}}{{}}}
\bibcite{abdi_partial_2003}{{8}{}{{}}{{}}}
\bibcite{breiman_random_2001}{{9}{}{{}}{{}}}
\bibcite{lecun_generalization_1989}{{10}{}{{}}{{}}}
\bibcite{ghaffari_metabolomics_2019}{{11}{}{{}}{{}}}
\bibcite{rovere_prediction_2021}{{12}{}{{}}{{}}}
\bibcite{becker_predicting_2021}{{13}{}{{}}{{}}}
\bibcite{lahart_predicting_2019}{{14}{}{{}}{{}}}
\bibcite{bresolin_infrared_2020}{{15}{}{{}}{{}}}
\bibcite{grelet_potential_2020}{{16}{}{{}}{{}}}
\bibcite{adriaens_productive_2020}{{17}{}{{}}{{}}}
\bibcite{mota_real-time_2022}{{18}{}{{}}{{}}}
\bibcite{spoliansky_development_2016}{{19}{}{{}}{{}}}
\bibcite{yukun_automatic_2019}{{20}{}{{}}{{}}}
\bibcite{song_automated_2018}{{21}{}{{}}{{}}}
\bibcite{xavier_use_2022}{{22}{}{{}}{{}}}
\bibcite{mantysaari_body_2019}{{23}{}{{}}{{}}}
\bibcite{frizzarin_predicting_2021}{{24}{}{{}}{{}}}
\bibcite{appuhamy_prediction_2016}{{25}{}{{}}{{}}}
\bibcite{de_souza_predicting_2018}{{26}{}{{}}{{}}}
\bibcite{dorea_mining_2018}{{27}{}{{}}{{}}}
\bibcite{lin_concordance_1989}{{28}{}{{}}{{}}}
\bibcite{jones_identifying_2022}{{29}{}{{}}{{}}}
\bibcite{oleary_invited_2020}{{30}{}{{}}{{}}}
\bibcite{stojkov_hot_2018}{{31}{}{{}}{{}}}
\bibcite{alsaaod_automatic_2019}{{32}{}{{}}{{}}}
\bibcite{kang_accurate_2020}{{33}{}{{}}{{}}}
\bibcite{denholm_predicting_2020}{{34}{}{{}}{{}}}
\bibcite{kandeel_ability_2019}{{35}{}{{}}{{}}}
\bibcite{chicco_advantages_2020}{{36}{}{{}}{{}}}
\bibcite{bowen_early_2021}{{37}{}{{}}{{}}}
\bibcite{metz_note_2020}{{38}{}{{}}{{}}}
\bibcite{chen_independent_2023}{{39}{}{{}}{{}}}
\bibcite{haque_recognition_2023}{{40}{}{{}}{{}}}
\bibcite{sibiya_computational_2019}{{41}{}{{}}{{}}}
\bibcite{zoph_neural_2017}{{42}{}{{}}{{}}}
\bibcite{soares_successive_2013}{{43}{}{{}}{{}}}
\bibcite{zhang_automated_2019}{{44}{}{{}}{{}}}
\bibcite{shahinfar_prediction_2019}{{45}{}{{}}{{}}}
\bibcite{st-pierre_invited_2001}{{46}{}{{}}{{}}}
\bibcite{de_oliveira_genomic_2020}{{47}{}{{}}{{}}}
\bibcite{lopez-cruz_leveraging_2023}{{48}{}{{}}{{}}}
\bibcite{buczinski_validation_2018}{{49}{}{{}}{{}}}
\bibcite{lu_-field_2017}{{50}{}{{}}{{}}}
\bibcite{su_advanced_2020}{{51}{}{{}}{{}}}
\bibcite{gao_retrieval-augmented_2024}{{52}{}{{}}{{}}}
\bibcite{salemi_evaluating_2024}{{53}{}{{}}{{}}}
\bibcite{minni_exploring_2024}{{54}{}{{}}{{}}}
\newlabel{eq_datasplit}{{S.1}{45}{Cross Validation}{equation.6.1}{}}
\newlabel{eq_traintest}{{S.2}{45}{Cross Validation}{equation.6.2}{}}
\newlabel{eq_g_est}{{S.3}{45}{Cross Validation}{equation.6.3}{}}
\newlabel{eq_g_exp}{{S.4}{46}{Cross Validation}{equation.6.4}{}}
\newlabel{eq_bias}{{S.5}{46}{Cross Validation Bias and Variance}{equation.6.5}{}}
\newlabel{eq_var}{{S.6}{46}{Cross Validation Bias and Variance}{equation.6.6}{}}
\newlabel{eq_tradeoff}{{S.7}{47}{Cross Validation Bias and Variance}{equation.6.7}{}}
\newlabel{eq_ols}{{S.8}{47}{Hyperparameter}{equation.6.8}{}}
\newlabel{eq_ridge}{{S.9}{47}{Hyperparameter}{equation.6.9}{}}
\newlabel{eq_lasso}{{S.10}{47}{Hyperparameter}{equation.6.10}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{eq_pf_cov}{{S.11}{48}{Sqaured Correlation Coefficient $r^2$ and Determination Coefficient $R^2$}{equation.6.11}{}}
\newlabel{eq_pf_r2}{{S.12}{48}{Sqaured Correlation Coefficient $r^2$ and Determination Coefficient $R^2$}{equation.6.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S.6}{\ignorespaces Experiment 2: ANOVA results of how each CV procedure affects the evaluation bias measured in the correlation coefficient (\textit  {r}). FS: Feature Selection, HT: Hyperparameter Tuning. DF: Degree of Freedom, SS: Sum of Squares, MS: Mean Squares. Significant p-values (< 0.05) are highlighted in bold.\relax }}{49}{table.caption.26}\protected@file@percent }
\newlabel{tab:anova_r}{{S.6}{49}{Experiment 2: ANOVA results of how each CV procedure affects the evaluation bias measured in the correlation coefficient (\textit {r}). FS: Feature Selection, HT: Hyperparameter Tuning. DF: Degree of Freedom, SS: Sum of Squares, MS: Mean Squares. Significant p-values (< 0.05) are highlighted in bold.\relax }{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {S.7}{\ignorespaces Experiment 3: ANOVA results for the effect of deploying block CV and random CV. DF: Degree of Freedom, SS: Sum of Squares, MS: Mean Squares. Significant p-values (< 0.05) are highlighted in bold.\relax }}{50}{table.caption.27}\protected@file@percent }
\newlabel{tab:anova_all}{{S.7}{50}{Experiment 3: ANOVA results for the effect of deploying block CV and random CV. DF: Degree of Freedom, SS: Sum of Squares, MS: Mean Squares. Significant p-values (< 0.05) are highlighted in bold.\relax }{table.caption.27}{}}
\gdef \@abspage@last{50}
