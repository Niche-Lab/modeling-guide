\section{Conclusion}

In summary, the review highlights several key considerations for performance assessment in predictive modeling. When evaluating regression models, the choice of metrics like Correlation Coefficient r, RMSE, and $R^2$ depends on the specific goals of the model. A comprehensive evaluation should include multiple metrics to understand different aspects of model performance. In binary classification models, precision and recall are crucial, but it is essential to correctly designate the positive class to avoid bias. Label-invariant metrics, such as the ROC curve and the proposed MCC curve, provide a balanced assessment, unaffected by class label choices.
Additionally, the reliability of model evaluation is significantly influenced by estimator choice and sample size. Larger sample sizes tend to reduce bias and variance, increasing evaluation reliability. Cross-validation methods, such as K-fold CV and LOOCV, are preferable for unbiased performance estimation, with the number of folds in K-fold CV being particularly influential in smaller datasets. Moreover, the review underscores the importance of correct implementation in model selection processes, as improper techniques can inflate performance estimates. This is especially true in complex models where feature selection and hyperparameter tuning need meticulous cross-validation to avoid overestimation of performance. Finally, the utility of Block CV is emphasized in contexts where block effects are significant. It provides a more realistic assessment of model generalizability and accuracy compared to a Random CV, which tends to overestimate performance in such scenarios.
Overall, the review recommends a thoughtful selection of metrics and evaluation techniques, tailored to the specific dataset and modeling objectives, to ensure accurate and reliable performance assessments in predictive modeling.

\section{Acknowledgement}
The author James Chen expresses his gratitude to Drs. Zhiwu Zhang, Hao Cheng, Gota Morota, and Gonzalo Ferreira for their insightful discussions that partially contributed to this study. The authors declare no conflicts of interest.